spark-md5-计算文件 MD5值

```bash
npm install --save spark-md5
```



```html
<body>
  <input type="file">
</body>
```



```js
const inpFile = document.querySelector('input[type=file]');

inpFile.onchange = async (e) => {
  const file = e.target.files[0];
  const chunks = await cutFile(file)
}
```



```js
// 分片方法
// 每个分片大小,5MB
const CHUNK_SIZE = 1024 * 1024 * 5;
async function cutFile(file) {
  // 分片数量
  const chunkCount = Math.ceil(file.size / CHUNK_SIZE);
  const result = []
  for (let i = 0; i < chunkCount; i++) {
    const chunk = await createChunk(file, i, CHUNK_SIZE)
    result.push(chunk)
  }

  return result
}
```



```js
import SparkMD5 from 'spark-md5'
/**
 * 创建分片
 * @param {File} file 文件
 * @param {number} index 分片索引
 * @param {number} chunkSize 分片大小
 */
function createChunk(file, index, chunkSize) {
  return new Promise((resolve) => {
    const start = index * chunkSize;
    const end = Math.min(start + chunkSize, file.size);
    const spark = new SparkMD5.ArrayBuffer()
    const fileReader = new FileReader();
    const blob = file.slice(start, end)
    fileReader.onload = (e) => {
      spark.append(e.target.result)

      resolve({
        start,
        end,
        index,
        hash: spark.end(),
        blob
      })
    }
    fileReader.readAsArrayBuffer(blob)
  })
}
```

在createChunk中为分片计算 MD5值的方法`spark.append(e.target.result)`计算量很大，会拖慢分片速度，还会导致画面中动画等卡顿，所以改成多线程，这样减轻了主线程的任务量。不是随便开进程，而是需要根据 cpu 的内核数

以下为使用多线程

```js
// 分片方法
// 每个分片大小,5MB
const CHUNK_SIZE = 1024 * 1024 * 5;
// cpu内核数
const THREAD_COUNT = navigator.hardwareConcurrency || 4;
// 线程完成任务的数
let finishCount = 0
async function cutFile(file) {
  return new Promise((resolve) => {
    // 分片数量
    const chunkCount = Math.ceil(file.size / CHUNK_SIZE);
    // 每个线程分到的切片数量
    const threadChunkCount = Math.ceil(chunkCount / THREAD_COUNT);
    const result = []

    for (let i = 0; i < THREAD_COUNT; i++) {
      // 创建一个线程并分配任务
      const worker = new Worker('./worker.js', {
        type: 'module'
      })
      const start = i * threadChunkCount
      const end = Math.min((i + 1) * threadChunkCount, chunkCount)

      worker.postMessage({
        file,
        CHUNK_SIZE,
        startChunkIndex: start,
        endChunkIndex: end
      })

      worker.onmessage = (e) => {
        for (let i = start; i < end; i++) {
          result[i] = e.data[i - start]
        }
        worker.terminate()
        finishCount++
        if (finishCount === THREAD_COUNT) {
          resolve(result)
        }
      }
    }
  })
}
```

```js
// worker.js
// 引入createChunk函数
onmessage = async e => {
  const {
    file,
    CHUNK_SIZE,
    startChunkIndex,
    endChunkIndex
  } = e.data
  
  const proms = []
  for (let i = startChunkIndex; i <= endChunkIndex; i++) {
    proms.push(createChunk(file, i, CHUNK_SIZE))
  }
  const chunks = await Promise.all(proms)
  postMessage(chunks)
}
```

